# ==============================================================================
# BLOCO 1: INSTALA√á√ïES E IMPORTA√á√ïES
# ==============================================================================
!pip install kmodes --quiet
!pip install tqdm --quiet
!pip install scikit-learn --quiet

import pandas as pd
import numpy as np
from kmodes.kprototypes import KPrototypes
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import LocalOutlierFactor
from io import BytesIO
import ipywidgets as widgets
from IPython.display import display, clear_output, FileLink
from tqdm.notebook import tqdm
from joblib import Parallel, delayed
from typing import List, Tuple, Dict, Any, Optional
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ==============================================================================
# BLOCO 2: FUN√á√ïES DE L√ìGICA E AN√ÅLISE (CORRE√á√ïES IMPLEMENTADAS)
# ==============================================================================
def reduzir_memoria(dataframe: pd.DataFrame) -> pd.DataFrame:
    """
    Reduz o uso de mem√≥ria do DataFrame convertendo tipos de dados num√©ricos.
    """
    for coluna in dataframe.select_dtypes(include=['float64']):
        dataframe[coluna] = pd.to_numeric(dataframe[coluna], downcast='float')
    for coluna in dataframe.select_dtypes(include=['int64']):
        dataframe[coluna] = pd.to_numeric(dataframe[coluna], downcast='integer')
    return dataframe

def identificar_variaveis(dataframe: pd.DataFrame) -> Tuple[List[str], List[str]]:
    """
    Identifica e retorna listas de vari√°veis categ√≥ricas e num√©ricas.
    """
    colunas_categoricas = dataframe.select_dtypes(include=['object', 'category']).columns.tolist()
    colunas_numericas = dataframe.select_dtypes(include=[np.number]).columns.tolist()
    return colunas_categoricas, colunas_numericas

def calcular_gamma_automatico(dataframe: pd.DataFrame, colunas_numericas: List[str]) -> float:
    """
    Calcula Gamma usando m√©todo robusto baseado na m√©dia dos desvios padr√£o padronizados.
    """
    if not colunas_numericas:
        return 0.5

    # Padronizar as vari√°veis antes de calcular os desvios padr√£o
    scaler = StandardScaler()
    dados_padronizados = scaler.fit_transform(dataframe[colunas_numericas])
    dados_padronizados_df = pd.DataFrame(dados_padronizados, columns=colunas_numericas)

    desvios_padrao = dados_padronizados_df.std()
    gamma = 0.5 * desvios_padrao.mean()

    print(f"üìä Gamma calculado automaticamente: {gamma:.4f}")
    return gamma

def detectar_e_tratar_outliers(dataframe: pd.DataFrame, colunas_numericas: List[str], remover_outliers: bool = True) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """
    Detecta e trata outliers usando m√∫ltiplos m√©todos de forma consistente.
    """
    informacoes_outliers = {
        'z_score': {'quantidade': 0, 'ids': []},
        'lof': {'quantidade': 0, 'ids': []},
        'total_detectados': 0,
        'ids_removidos': []
    }

    dataframe_limpo = dataframe.copy()
    todos_outliers = set()

    # M√©todo 1: Z-score com threshold conservador
    for coluna in colunas_numericas:
        if coluna in dataframe_limpo.columns:
            z_scores = np.abs((dataframe_limpo[coluna] - dataframe_limpo[coluna].mean()) / dataframe_limpo[coluna].std())
            outliers_z = dataframe_limpo[z_scores > 2.5]

            if not outliers_z.empty:
                informacoes_outliers['z_score']['quantidade'] += len(outliers_z)
                informacoes_outliers['z_score']['ids'].extend(outliers_z.index.tolist())
                todos_outliers.update(outliers_z.index)

    # M√©todo 2: Local Outlier Factor para detec√ß√£o multivariada
    if colunas_numericas and len(dataframe_limpo) > 20:  # LOF requer m√≠nimo de amostras
        try:
            lof = LocalOutlierFactor(n_neighbors=min(20, len(dataframe_limpo)//2), contamination=0.05)
            outliers_lof = lof.fit_predict(dataframe_limpo[colunas_numericas])
            outliers_indices = dataframe_limpo[outliers_lof == -1].index

            if len(outliers_indices) > 0:
                informacoes_outliers['lof']['quantidade'] = len(outliers_indices)
                informacoes_outliers['lof']['ids'] = outliers_indices.tolist()
                todos_outliers.update(outliers_indices)
        except Exception as e:
            print(f"‚ö†Ô∏è  Aviso na detec√ß√£o LOF: {e}")

    # Consolidar todos os outliers
    informacoes_outliers['total_detectados'] = len(todos_outliers)
    informacoes_outliers['ids_removidos'] = list(todos_outliers)

    # Remover outliers se solicitado
    if remover_outliers and todos_outliers:
        dataframe_limpo = dataframe_limpo.drop(todos_outliers)

    # Relat√≥rio de outliers
    if informacoes_outliers['total_detectados'] > 0:
        print("‚ö†Ô∏è  OUTLIERS DETECTADOS:")
        print(f"   Z-score: {informacoes_outliers['z_score']['quantidade']} outliers")
        print(f"   LOF (multivariados): {informacoes_outliers['lof']['quantidade']} outliers")
        print(f"   Total √∫nico: {informacoes_outliers['total_detectados']} outliers")

        if remover_outliers:
            print(f"   ‚úÖ {len(todos_outliers)} outliers removidos")
        else:
            print("   ‚ÑπÔ∏è  Outliers detectados mas n√£o removidos")
    else:
        print("‚úÖ Nenhum outlier detectado")

    return dataframe_limpo, informacoes_outliers

def preparar_matriz_para_kprototypes(dataframe: pd.DataFrame, colunas_usadas: List[str], colunas_categoricas: List[str], padronizar: bool = True) -> Tuple[np.ndarray, List[int]]:
    """
    Prepara a matriz de dados para o algoritmo K-Prototypes com valida√ß√£o robusta.
    """
    # Validar e filtrar colunas categ√≥ricas
    colunas_categoricas_validas = [col for col in colunas_categoricas if col in colunas_usadas]

    if len(colunas_categoricas_validas) != len(colunas_categoricas):
        colunas_nao_encontradas = set(colunas_categoricas) - set(colunas_usadas)
        print(f"‚ö†Ô∏è  Aviso: Colunas categ√≥ricas n√£o encontradas: {colunas_nao_encontradas}")

    matriz = dataframe[colunas_usadas].copy()
    colunas_numericas = [col for col in colunas_usadas if col not in colunas_categoricas_validas]

    # Padroniza√ß√£o de vari√°veis num√©ricas (se solicitado)
    if padronizar and colunas_numericas:
        scaler = StandardScaler()
        matriz[colunas_numericas] = scaler.fit_transform(matriz[colunas_numericas])
        print("‚úÖ Vari√°veis num√©ricas padronizadas")

    # Converter categ√≥ricas para string
    for coluna in colunas_categoricas_validas:
        matriz[coluna] = matriz[coluna].astype(str)

    # Calcular √≠ndices categ√≥ricos apenas para colunas v√°lidas
    indices_categoricos = [colunas_usadas.index(coluna) for coluna in colunas_categoricas_validas]

    return matriz.to_numpy(), indices_categoricos

def calcular_custo_kprototypes(k: int, matriz: np.ndarray, indices_categoricos: List[int], gamma: float) -> float:
    """
    Calcula o custo para um determinado K com Gamma espec√≠fico.
    """
    try:
        kprototypes = KPrototypes(
            n_clusters=k,
            init='Cao',
            random_state=42,
            n_init=3,
            gamma=gamma,
            verbose=0
        )
        kprototypes.fit_predict(matriz, categorical=indices_categoricos)
        return kprototypes.cost_
    except Exception as erro:
        print(f"‚ùå Erro ao calcular custo para K={k}: {erro}")
        return float('inf')

def executar_metodo_elbow(dataframe: pd.DataFrame, colunas_usadas: List[str], colunas_categoricas: List[str], k_maximo: int, gamma: float) -> Tuple[int, List[float]]:
    """
    Executa o m√©todo Elbow com tratamento robusto de erros.
    """
    try:
        matriz, indices_categoricos = preparar_matriz_para_kprototypes(dataframe, colunas_usadas, colunas_categoricas, padronizar=True)
        intervalo_k = range(2, min(k_maximo + 1, len(dataframe) // 3))  # Limite m√°ximo seguro

        if len(intervalo_k) < 2:
            print("‚ö†Ô∏è  Intervalo K muito pequeno para an√°lise Elbow")
            return 3, []

        with tqdm(total=len(intervalo_k), desc="Calculando Elbow") as barra_progresso:
            custos = Parallel(n_jobs=-1)(
                delayed(calcular_custo_kprototypes)(k, matriz, indices_categoricos, gamma) for k in intervalo_k
            )
            barra_progresso.update(len(intervalo_k))

        # Filtrar valores infinitos
        custos_validos = [c for c in custos if c != float('inf')]
        if not custos_validos:
            print("‚ùå Todos os c√°lculos de custo falharam")
            return 3, []

        # Plotar gr√°fico Elbow
        plt.figure(figsize=(12, 6))
        plt.plot(intervalo_k[:len(custos_validos)], custos_validos, marker='o', linestyle='--', linewidth=2, markersize=8)
        plt.xlabel('N√∫mero de Clusters (K)', fontsize=12)
        plt.ylabel('Custo (Soma das Dist√¢ncias)', fontsize=12)
        plt.title(f'M√©todo Elbow para K-Prototypes (Gamma: {gamma:.2f})', fontsize=14)
        plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)
        plt.xticks(intervalo_k[:len(custos_validos)])

        # Calcular ponto do cotovelo
        k_sugerido = 3
        if len(custos_validos) > 2:
            # M√©todo da segunda derivada (diferen√ßas das diferen√ßas)
            diferencas = [custos_validos[i-1] - custos_validos[i] for i in range(1, len(custos_validos))]
            if diferencas:
                # Encontrar ponto de maior acelera√ß√£o negativa
                diferencas_segundas = [diferencas[i-1] - diferencas[i] for i in range(1, len(diferencas))]
                if diferencas_segundas:
                    k_sugerido = diferencas_segundas.index(max(diferencas_segundas)) + 2
                    plt.plot(k_sugerido, custos_validos[k_sugerido-2], 'ro', markersize=10, label=f'Cotovelo (K={k_sugerido})')
                    plt.legend()

        plt.tight_layout()
        plt.show()

        print(f"\nüìå An√°lise do Gr√°fico Sugere K = {k_sugerido}")
        return k_sugerido, custos_validos

    except Exception as e:
        print(f"‚ùå Erro no m√©todo Elbow: {e}")
        return 3, []

def gerar_clusterizacao(dataframe: pd.DataFrame, colunas_categoricas: List[str], colunas_numericas: List[str], k: int, gamma: float, remover_outliers: bool = True) -> Tuple[pd.DataFrame, any, Dict[str, Any]]:
    """
    Executa a clusteriza√ß√£o final com tratamento consistente de outliers.
    """
    colunas_usadas = colunas_categoricas + colunas_numericas

    # Tratar outliers antes da clusteriza√ß√£o
    dataframe_limpo, info_outliers = detectar_e_tratar_outliers(dataframe, colunas_numericas, remover_outliers)

    print(f"\n‚è≥ Executando clusteriza√ß√£o com {len(dataframe_limpo)} registros...")
    print(f"   Par√¢metros: K={k}, Gamma={gamma:.2f}, Outliers removidos: {remover_outliers}")

    try:
        matriz, indices_categoricos = preparar_matriz_para_kprototypes(dataframe_limpo, colunas_usadas, colunas_categoricas, padronizar=True)

        kprototypes = KPrototypes(
            n_clusters=k,
            init='Cao',
            random_state=42,
            n_init=5,
            verbose=1,
            gamma=gamma
        )

        clusters = kprototypes.fit_predict(matriz, categorical=indices_categoricos)

        dataframe_clusterizado = dataframe_limpo.copy()
        dataframe_clusterizado['cluster'] = clusters
        dataframe_clusterizado['cluster'] = dataframe_clusterizado['cluster'].astype('category')

        # Adicionar informa√ß√£o de outliers ao DataFrame original de forma n√£o destrutiva
        if 'outlier' in dataframe.columns:
            dataframe = dataframe.drop(columns=['outlier'])

        dataframe['outlier'] = dataframe.index.isin(info_outliers['ids_removidos'])

        print("‚úÖ Clusteriza√ß√£o conclu√≠da com sucesso!")
        return dataframe_clusterizado, kprototypes, info_outliers

    except Exception as e:
        print(f"‚ùå Erro na clusteriza√ß√£o: {e}")
        raise

def analisar_clusters(dataframe_clusterizado: pd.DataFrame, colunas_numericas: List[str], colunas_categoricas: List[str]):
    """
    Realiza an√°lise detalhada dos clusters gerados.
    """
    print("\nüìä AN√ÅLISE DETALHADA DOS CLUSTERS:")
    print("=" * 60)

    clusters_ordenados = sorted(dataframe_clusterizado['cluster'].unique())

    for cluster in clusters_ordenados:
        dados_cluster = dataframe_clusterizado[dataframe_clusterizado['cluster'] == cluster]

        print(f"\nüî∏ CLUSTER {cluster} ({len(dados_cluster)} registros):")

        # Estat√≠sticas num√©ricas
        if colunas_numericas:
            print(f"   üìà Estat√≠sticas num√©ricas:")
            for coluna in colunas_numericas:
                if coluna in dados_cluster.columns:
                    print(f"      {coluna}: {dados_cluster[coluna].mean():.2f} ¬± {dados_cluster[coluna].std():.2f}")

        # Distribui√ß√£o categ√≥rica
        if colunas_categoricas:
            print(f"   üéØ Distribui√ß√£o categ√≥rica:")
            for coluna in colunas_categoricas:
                if coluna in dados_cluster.columns:
                    distribuicao = dados_cluster[coluna].value_counts().head(3)  # Top 3 categorias
                    for valor, quantidade in distribuicao.items():
                        percentual = (quantidade / len(dados_cluster)) * 100
                        print(f"      {coluna}_{valor}: {quantidade} ({percentual:.1f}%)")

        # An√°lise de performance educacional
        if 'nota_final' in dados_cluster.columns:
            nota_media = dados_cluster['nota_final'].mean()
            if nota_media >= 7.0:
                status = "‚úÖ Excelente desempenho"
            elif nota_media >= 5.0:
                status = "‚ö†Ô∏è  Desempenho regular"
            else:
                status = "‚ùå Desempenho cr√≠tico"
            print(f"   üìä {status} (nota m√©dia: {nota_media:.2f})")

def visualizar_clusters_pca(dataframe_clusterizado: pd.DataFrame, colunas_categoricas: List[str], colunas_numericas: List[str]):
    """
    Visualiza√ß√£o robusta dos clusters com PCA.
    """
    try:
        dataframe_pca = dataframe_clusterizado[colunas_categoricas + colunas_numericas].copy()

        # Padronizar vari√°veis num√©ricas
        if colunas_numericas:
            scaler = StandardScaler()
            dataframe_pca[colunas_numericas] = scaler.fit_transform(dataframe_pca[colunas_numericas])

        # Converter vari√°veis categ√≥ricas usando one-hot encoding
        if colunas_categoricas:
            dataframe_pca = pd.get_dummies(dataframe_pca, columns=colunas_categoricas, drop_first=True, dummy_na=True)

        if dataframe_pca.shape[1] < 2:
            print("‚ö†Ô∏è PCA requer pelo menos 2 colunas para visualiza√ß√£o.")
            return

        # Executar PCA
        pca = PCA(n_components=2)
        x_reduzido = pca.fit_transform(dataframe_pca)
        variancia_explicada = sum(pca.explained_variance_ratio_) * 100

        # Criar visualiza√ß√£o
        plt.figure(figsize=(14, 10))

        # Mapear clusters para cores consistentes
        clusters_unicos = sorted(dataframe_clusterizado['cluster'].unique())
        cores = plt.cm.tab10(np.linspace(0, 1, len(clusters_unicos)))
        mapeamento_cores = dict(zip(clusters_unicos, cores))

        # Scatter plot com cores mapeadas
        for cluster in clusters_unicos:
            indices = dataframe_clusterizado['cluster'] == cluster
            plt.scatter(x_reduzido[indices, 0], x_reduzido[indices, 1],
                       c=[mapeamento_cores[cluster]], label=f'Cluster {cluster}',
                       s=100, alpha=0.7, edgecolors='w', linewidth=0.5)

        plt.title('Visualiza√ß√£o dos Clusters com PCA\n(An√°lise de Segmenta√ß√£o)', fontsize=16, pad=20)
        plt.xlabel(f'Componente Principal 1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)
        plt.ylabel(f'Componente Principal 2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)

        plt.legend(title="Clusters", loc='best', frameon=True, fancybox=True)
        plt.grid(True, linestyle='--', alpha=0.3)

        # Informa√ß√£o de qualidade
        plt.figtext(0.02, 0.02, f'Vari√¢ncia explicada: {variancia_explicada:.1f}%\n'
                               f'Total de clusters: {len(clusters_unicos)}\n'
                               f'Total de regisros: {len(dataframe_clusterizado)}',
                    fontsize=10, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"))

        plt.tight_layout()
        plt.show()

        print(f"\nüìä Qualidade da Visualiza√ß√£o:")
        print(f"   ‚úÖ Vari√¢ncia explicada: {variancia_explicada:.1f}%")
        if variancia_explicada < 50:
            print("   ‚ö†Ô∏è  Representa√ß√£o 2D pode n√£o capturar toda a estrutura dos dados")
        else:
            print("   ‚úÖ Boa representa√ß√£o da estrutura multidimensional")

    except Exception as e:
        print(f"‚ùå Erro na visualiza√ß√£o PCA: {e}")

def gerar_relatorio_completo(dataframe_clusterizado: pd.DataFrame, info_outliers: Dict[str, Any]) -> str:
    """
    Gera relat√≥rio completo com metadados separados.
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # Nome do arquivo principal
    nome_arquivo_csv = f'clusterizacao_{timestamp}.csv'

    # Salvar CSV limpo
    dataframe_clusterizado.to_csv(nome_arquivo_csv, index=False)

    # Salvar metadados em arquivo separado
    nome_arquivo_meta = f'metadados_clusterizacao_{timestamp}.txt'
    metadados = [
        "RELAT√ìRIO DE CLUSTERIZA√á√ÉO K-PROTOTYPES",
        "=" * 50,
        f"Data de gera√ß√£o: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"Total de clusters: {dataframe_clusterizado['cluster'].nunique()}",
        f"Total de registros: {len(dataframe_clusterizado)}",
        f"Outliers detectados: {info_outliers['total_detectados']}",
        f"Outliers removidos: {len(info_outliers['ids_removidos'])}",
        f"Vari√°veis utilizadas: {', '.join([col for col in dataframe_clusterizado.columns if col != 'cluster'])}",
        "\nESTAT√çSTICAS POR CLUSTER:",
        "-" * 30
    ]

    # Adicionar estat√≠sticas por cluster
    for cluster in sorted(dataframe_clusterizado['cluster'].unique()):
        dados_cluster = dataframe_clusterizado[dataframe_clusterizado['cluster'] == cluster]
        metadados.append(f"Cluster {cluster}: {len(dados_cluster)} registros")

    with open(nome_arquivo_meta, 'w', encoding='utf-8') as f:
        f.write('\n'.join(metadados))

    display(widgets.HTML(f"""
    <h4>‚úÖ Relat√≥rios gerados:</h4>
    <ul>
    <li><code>{nome_arquivo_csv}</code> - Dados clusterizados</li>
    <li><code>{nome_arquivo_meta}</code> - Metadados e estat√≠sticas</li>
    </ul>
    """))

    display(FileLink(nome_arquivo_csv))
    display(FileLink(nome_arquivo_meta))

    return nome_arquivo_csv

# ==============================================================================
# BLOCO 3: INTERFACE DO USU√ÅRIO (CORRIGIDA)
# ==============================================================================
def criar_interface_clusterizacao(dataframe: pd.DataFrame, colunas_categoricas: List[str], colunas_numericas: List[str]):
    """
    Cria interface interativa com controles funcionais.
    """
    saida_principal = widgets.Output()

    # Widgets de sele√ß√£o de vari√°veis
    checkboxes_categoricas = [widgets.Checkbox(value=True, description=coluna, indent=False)
                             for coluna in colunas_categoricas]
    checkboxes_numericas = [widgets.Checkbox(value=True, description=coluna, indent=False)
                           for coluna in colunas_numericas]

    # Widgets de configura√ß√£o (agora funcionais)
    checkbox_padronizar = widgets.Checkbox(value=True, description='Padronizar vari√°veis num√©ricas', indent=False)
    checkbox_remover_outliers = widgets.Checkbox(value=True, description='Remover outliers', indent=False)

    slider_gamma = widgets.FloatSlider(value=0.5, min=0.1, max=3.0, step=0.1, description='Gamma:')
    checkbox_gamma_auto = widgets.Checkbox(value=True, description='Gamma autom√°tico', indent=False)

    slider_k = widgets.IntSlider(value=3, min=2, max=10, step=1, description='K Clusters:')
    slider_k_maximo = widgets.IntSlider(value=8, min=4, max=15, step=1, description='K m√°ximo (Elbow):')

    # Bot√µes
    botao_elbow = widgets.Button(description="üìä Executar An√°lise Elbow", button_style='info')
    botao_clusterizar = widgets.Button(description="üöÄ Executar Clusteriza√ß√£o", button_style='success')
    botao_clusterizar.layout.display = 'none'

    # Callbacks melhorados
    def alternar_controles(mudanca):
        slider_gamma.disabled = checkbox_gamma_auto.value

    checkbox_gamma_auto.observe(alternar_controles, names='value')

    def ao_clicar_elbow(botao):
        with saida_principal:
            clear_output(wait=True)

            colunas_cat_selecionadas = [cb.description for cb in checkboxes_categoricas if cb.value]
            colunas_num_selecionadas = [cb.description for cb in checkboxes_numericas if cb.value]

            if not colunas_cat_selecionadas and not colunas_num_selecionadas:
                print("‚ùå Selecione pelo menos uma vari√°vel.")
                return

            # Calcular Gamma
            if checkbox_gamma_auto.value:
                gamma = calcular_gamma_automatico(dataframe, colunas_num_selecionadas)
            else:
                gamma = slider_gamma.value

            print("üìã Configura√ß√£o selecionada:")
            print(f"   Vari√°veis categ√≥ricas: {colunas_cat_selecionadas}")
            print(f"   Vari√°veis num√©ricas: {colunas_num_selecionadas}")
            print(f"   Gamma: {gamma:.3f}")
            print(f"   K m√°ximo: {slider_k_maximo.value}")

            # Executar an√°lise Elbow
            k_sugerido, custos = executar_metodo_elbow(
                dataframe,
                colunas_cat_selecionadas + colunas_num_selecionadas,
                colunas_cat_selecionadas,
                slider_k_maximo.value,
                gamma
            )

            if custos:  # S√≥ atualizar se Elbow foi bem-sucedido
                slider_k.value = k_sugerido
                botao_clusterizar.layout.display = 'inline-block'

    def ao_clicar_clusterizar(botao):
        with saida_principal:
            clear_output(wait=True)

            colunas_cat_selecionadas = [cb.description for cb in checkboxes_categoricas if cb.value]
            colunas_num_selecionadas = [cb.description for cb in checkboxes_numericas if cb.value]

            if not colunas_cat_selecionadas and not colunas_num_selecionadas:
                print("‚ùå Selecione pelo menos uma vari√°vel.")
                return

            # Calcular Gamma
            if checkbox_gamma_auto.value:
                gamma = calcular_gamma_automatico(dataframe, colunas_num_selecionadas)
            else:
                gamma = slider_gamma.value

            print("üéØ Iniciando clusteriza√ß√£o final...")
            print(f"   K: {slider_k.value}")
            print(f"   Gamma: {gamma:.3f}")
            print(f"   Padroniza√ß√£o: {'Sim' if checkbox_padronizar.value else 'N√£o'}")
            print(f"   Remo√ß√£o de outliers: {'Sim' if checkbox_remover_outliers.value else 'N√£o'}")

            try:
                # Executar clusteriza√ß√£o
                dataframe_clusterizado, modelo, info_outliers = gerar_clusterizacao(
                    dataframe, colunas_cat_selecionadas, colunas_num_selecionadas,
                    slider_k.value, gamma, checkbox_remover_outliers.value
                )

                # An√°lise dos resultados
                analisar_clusters(dataframe_clusterizado, colunas_num_selecionadas, colunas_cat_selecionadas)

                # Visualiza√ß√£o
                visualizar_clusters_pca(dataframe_clusterizado, colunas_cat_selecionadas, colunas_num_selecionadas)

                # Download
                gerar_relatorio_completo(dataframe_clusterizado, info_outliers)

                print("\n‚úÖ Processo conclu√≠do com sucesso!")

            except Exception as e:
                print(f"‚ùå Erro durante a clusteriza√ß√£o: {e}")
                import traceback
                traceback.print_exc()

    # Configurar eventos
    botao_elbow.on_click(ao_clicar_elbow)
    botao_clusterizar.on_click(ao_clicar_clusterizar)

    # Layout da interface
    interface = widgets.VBox([
        widgets.HTML("<h3>üîß Configura√ß√£o da Clusteriza√ß√£o</h3>"),

        widgets.HTML("<h4>üìã Selecione as vari√°veis:</h4>"),
        widgets.HTML("<strong>Vari√°veis Categ√≥ricas:</strong>"),
        widgets.VBox(checkboxes_categoricas),
        widgets.HTML("<strong>Vari√°veis Num√©ricas:</strong>"),
        widgets.VBox(checkboxes_numericas),

        widgets.HTML("<h4>‚öôÔ∏è Configura√ß√µes Avan√ßadas:</h4>"),
        checkbox_padronizar,
        checkbox_remover_outliers,
        widgets.HBox([checkbox_gamma_auto, slider_gamma]),

        widgets.HTML("<h4>üìä Configura√ß√£o de Clusters:</h4>"),
        widgets.HBox([widgets.Label("K sugerido:"), slider_k]),
        widgets.HBox([widgets.Label("K m√°ximo (Elbow):"), slider_k_maximo]),

        widgets.HTML("<br>"),
        widgets.HBox([botao_elbow, botao_clusterizar]),
        saida_principal
    ])

    return interface

# ==============================================================================
# BLOCO 4: EXECU√á√ÉO PRINCIPAL
# ==============================================================================
def main():
    """Fun√ß√£o principal de execu√ß√£o do script."""

    # Verificar se estamos no Google Colab
    try:
        from google.colab import files
        is_colab = True
    except ImportError:
        is_colab = False
        print("‚ö†Ô∏è  Ambiente n√£o detectado como Google Colab")
        print("   Algumas funcionalidades podem n√£o estar dispon√≠veis")

    botao_carregar = widgets.Button(
        description="üìÇ Carregar Arquivo CSV",
        button_style='primary',
        icon='folder'
    )

    area_saida = widgets.Output()

    def ao_carregar_arquivo(botao):
        with area_saida:
            clear_output()

            if not is_colab:
                print("‚ùå Upload de arquivo s√≥ dispon√≠vel no Google Colab")
                print("   Use um arquivo local ou execute no Google Colab")
                return

            print("‚è≥ Aguardando upload do arquivo...")

            try:
                arquivos = files.upload()
                if not arquivos:
                    print("‚ùå Nenhum arquivo selecionado.")
                    return

                nome_arquivo = list(arquivos.keys())[0]
                dados = pd.read_csv(BytesIO(arquivos[nome_arquivo]))
                dados = reduzir_memoria(dados)

                # Processar dados
                colunas_categoricas = dados.select_dtypes(include=['object']).columns
                dados[colunas_categoricas] = dados[colunas_categoricas].astype(str)

                colunas_cat, colunas_num = identificar_variaveis(dados)

                print(f"‚úÖ Arquivo carregado: {nome_arquivo}")
                print(f"üìä Dimens√µes: {dados.shape[0]} linhas √ó {dados.shape[1]} colunas")
                print(f"üîç Vari√°veis categ√≥ricas: {colunas_cat}")
                print(f"üî¢ Vari√°veis num√©ricas: {colunas_num}")

                # Mostrar pr√©via
                display(dados.head(3))

                # Iniciar interface
                interface = criar_interface_clusterizacao(dados, colunas_cat, colunas_num)
                display(interface)

            except Exception as erro:
                print(f"‚ùå Erro ao processar arquivo: {erro}")
                print("   Verifique se o arquivo √© um CSV v√°lido.")

    botao_carregar.on_click(ao_carregar_arquivo)

    # Interface inicial
    display(widgets.HTML("""
    <h1>üéØ Sistema de Clusteriza√ß√£o K-Prototypes</h1>
    <p>Ferramenta avan√ßada para segmenta√ß√£o de dados com detec√ß√£o de outliers</p>
    <p><strong>‚ú® Funcionalidades:</strong></p>
    <ul>
    <li>‚úÖ Clusteriza√ß√£o com vari√°veis mistas (num√©ricas + categ√≥ricas)</li>
    <li>‚úÖ Detec√ß√£o robusta de outliers (Z-score + LOF)</li>
    <li>‚úÖ An√°lise Elbow para determina√ß√£o do K ideal</li>
    <li>‚úÖ Visualiza√ß√£o PCA interativa</li>
    <li>‚úÖ Relat√≥rios completos em CSV + metadados</li>
    </ul>
    """))

    display(botao_carregar)
    display(area_saida)

# ==============================================================================
# EXECU√á√ÉO
# ==============================================================================
if __name__ == "__main__":
    main()